# Максимальное значение элементов матрицы
- Студент: Иванова Полина Сергеевна, группа 3823Б1ПР1
- Технология: SEQ | MPI
- Вариант: 13


## 1. Введение

Задача поиска максимального элемента в матрице является фундаментальной операцией в вычислительной математике и имеет широкое применение в обработке изображений, машинном обучении и научных вычислениях. При работе с большими матрицами последовательные алгоритмы становятся недостаточно эффективными.

Ожидаемым результатом моей работы является реализация и сравнение последовательного и MPI-параллельного алгоритмов для поиска максимального элемента в матрице с учетом эффективного распределения данных.
---

## 2. Постановка задачи

**Цель работы:**  
Реализовать последовательную и параллельную версии алгоритма поиска максимального элемента в матрице, а также провести сравнение их эффективности.

**Определение задачи:**  
Для заданной матрицы M размером m×n необходимо найти элемент с максимальным значением. Формально:
max_value = max(M[i][j]) для всех i ∈ [0, m-1], j ∈ [0, n-1]

**Ограничения:**
- Входные данные - матрица произвольного размера (включая пустые матрицы)
- Матрица может быть как квадратной, так и прямоугольной
- Должна обеспечиваться корректная обработка граничных случаев
- Для параллельной реализации используется MPI
- Результат обеих реализаций (последовательной и параллельной) должен совпадать

---

## 3. Базовый алгоритм

### Алгоритм последовательной реализации

1. Инициализация
- Получить на вход матрицу: matrix
- Инициализировать переменную максимума: max_val = INT_MIN

2. Обход матрицы
- Для каждой строки i от 0 до rows-1:
 - Для каждого столбца j от 0 до cols-1:
  - Если matrix[i][j] > max_val, то max_val = matrix[i][j]

3. Возврат результата
- Вернуть значение max_val

Код последовательной реализации:


### Код последовательной реализации:

```CPP
bool IvanovaPMaxMatrixSEQ::RunImpl() {
  int max_val = std::numeric_limits<int>::min();

  for(size_t i = 0; i < GetInput().size(); i++) {
    for (size_t j = 0; j < GetInput()[i].size(); j++) {
      if (GetInput()[i][j] > max_val) {
        max_val = GetInput()[i][j];
      }
    }
  }

  GetOutput() = max_val;
  return true;
}
```

---

## 4. Схема распараллеливания

### Распределение данных

Для параллельной обработки используется распределение строк матрицы между процессами с балансировкой нагрузки.

- Общее количество строк: 'total_rows = matrix.size()`
- Базовая длина блока: 'block_size = total_rows / num_processes`
- Остаток: 'remainder = total_rows % num_processes`

Распределение выполняется с учетом остатка для равномерной нагрузки:

- Процессы с рангом 'i < remainder` получают на 1 строку больше
- Каждый процесс обрабатывает диапазон строк '[start_row, end_row)`

### Схема связи и топология

Используется звездообразная топология с процессом 0 в качестве центрального координатора.   Все коммуникации проходят через процесс 0:  
- Нисходящие связи: от процесса 0 к worker-процессам (рассылка данных)  
- Восходящие связи: от worker-процессов к процессу 0 (передача локальных максимумов)  

Схема коммуникации представляет собой двухэтапный процесс:
1. Фаза сбора: Worker-процессы отправляют свои локальные максимумы процессу 0
2. Фаза рассылки: Процесс 0 рассылает глобальный максимум всем процессам

### Ранжирование ролей

Процесс 0 (Мастер-координатор):
  - Распределяет данные между процессами
  - Выполняет локальную обработку своей части данных
  - Принимает локальные максимумы от всех worker-процессов
  - Находит глобальный максимум
  - Рассылает конечный результат всем процессам

Процессы 1..N-1 (Worker-процессы):
  - Получают свои сегменты данных
  - Обрабатывают назначенные строки матрицы
  - Отправляют свои локальные максимумы процессу 0

### Декомпозиция
По данным: строки матрицы делятся на непрерывные блоки
По функциям:
1. Локальный поиск максимума (все процессы)
2. Сбор результатов (процесс 0)
3. Синхронизация (рассылка итога)

### Планирование

1. Инициализация: расчет границ блоков и распределение данных
2. Локальная обработка: поиск максимума в назначенных строках
3. Сбор результатов: передача локальных максимумов процессу 0
4. Глобальная редукция: нахождение общего максимума
5. Синхронизация: рассылка финального результата

### Псевдокод MPI-реализации

```
функция RunImpl():
    rank, size = MPI_Comm_rank(), MPI_Comm_size()
    rows, cols = получить_размеры_матрицы()
    
    // Распределение работы по строкам
    rows_per_process = распределить_строки(rows, size, rank)
    
    // Подготовка данных для scatterv
    если rank == 0:
        подготовить_буфер_рассылки()
    
    // Рассылка данных
    local_data = получить_локальные_данные(rows_per_process, cols)
    
    // Локальные вычисления
    local_max = найти_локальный_максимум(local_data)
    
    // Глобальная редукция
    global_max = выполнить_MPI_Reduce(local_max, MPI_MAX)
    
    // Синхронизация результата
    GetOutput() = global_max
```

---
## 5. Детали реализации

### Структура кода

**Файловая структура:**

ivanova_p_max_matrix/  
├── common/include/common.hpp
├── data/matrix_generator.hpp 
├── seq/include/ops_seq.hpp  
├── seq/src/ops_seq.cpp  
├── mpi/include/ops_mpi.hpp  
├── mpi/src/ops_mpi.cpp  
├── tests/functional/main.cpp  
└── tests/perfomance/main.cpp


**Ключевые классы и файлы:**

1. Последовательная реализация ('seq'):
   - `ops_seq.hpp' - объявление класса 'IvanovaPMaxMatrixSEQ`
   - `ops_seq.cpp' - реализация методов:
     - `RunImpl()' - основной алгоритм поиска максимума
     - `PreProcessingImpl()' - инициализация
     - `ValidationImpl()' - проверка корректности матрицы

2. MPI реализация ('mpi'):
   - `ops_mpi.hpp' - объявление класса 'IvanovaPMaxMatrixSEQ`
   - `ops_mpi.cpp' - реализация методов:
     - `RunImpl()' - координация параллельных вычислений
     - `ValidationImpl()' - проверка корректности данных

3. Общие компоненты («обычные»):
   - `common.hpp' - общие типы данных и константы
   - `matrix_generator.hpp' - генератор тестовых матриц

**Архитектурные особенности:**
- Разделение интерфейса (.hpp) и реализации (.cpp)
- Единый стиль именования для обеих реализаций
- Изолированные тестовые модули для функциональности и производительности

### Важные допущения и ограничения

**Обработка данных:**
- Поддержка матриц произвольного размера
  - Максимальное количество строк: 'std::vector<std::vector<int>>::max_size()`
  - Максимальное количество столбцов: 'std::vector<int>::max_size()`
  - Максимальный общий размер: ограничено доступной оперативной памятью
- Корректная обработка целочисленных значений
- Обработка пустых матриц и матриц с одним элементом  

**Граничные случаи:**
```CPP
max({{}}) = INT_MIN                    // Пустая матрица
max({{42}}) = 42                       // Один элемент
max({{1, 2}, {3, 4}}) = 4             // Квадратная матрица
max({{-1, -5}, {-3, -2}}) = -1        // Отрицательные значения
```
### Рекомендации по использованию памяти
- Для матриц размером до 1000×1000 использовать последовательную версию
- Для больших матриц (>5000×5000) применять MPI версию
- Оптимальное количество процессов: 4-8 для большинства случаев
---
## 6. Экспериментальная установка
### Аппаратное обеспечение и ОС
Системные характеристики:
- Модель процессора: AMD Ryzen 7 5700U (8-ядерный процессор)
- Архитектура: Lucienne-U (Zen 2, x86-64)
- Ядра/потоки: 8 ядер, 16 потоков
- Оперативная память: 16 GB 
- Операционная система: Windows 10
- Тип системы: Ноутбук (HP Laptop 15s-eq2034ur)

### Набор инструментов
Компиляция и сборка:
- Компилятор:  g++ 13.3.0
- Стандарт языка: C++17
- Среда разработки: Visual Studio Code
- Тип сборки: Release
- Система сборки: CMake

## 7. Результаты и обсуждение

### 7.1 Корректность

**Методы проверки корректности:**

1. Эталонная функция сравнения:
- Реализована функция прямого поиска максимума для проверки
- Используется поэлементное сравнение всех элементов матрицы

2. Комплексное модульное тестирование:
- Функциональные тесты - проверка базовых сценариев
- Тесты покрытия - обработка граничных случаев

3. Тестирование производительности:
- Тестирование на матрицах различных размеров
- Сравнение времени выполнения SEQ и MPI версий

**Ключевые тестовые сценарии:**
```CPP
{{}} → INT_MIN                    // Пустая матрица
{{42}} → 42                       // Один элемент  
{{1, 2, 3}, {4, 5, 6}} → 6       // Прямоугольная матрица
{{-1, -5}, {-3, -2}} → -1        // Отрицательные значения
{{5, 3, 8}, {1, 9, 2}} → 9       // Максимум в середине
```
**Методология проверки:**
- Каждый тест выполняется для обеих реализаций (SEQ и MPI)
- Результаты сравниваются с эталонным значением
- Проверяется идентичность результатов между SEQ и MPI версиями
- Используется фреймворк (Google Test) для автоматизированной проверки

**Результаты проверки корректности:**
- Все функциональные тесты пройдены успешно
- Тесты на производительность подтвердили работоспособность на больших данных
- Результаты SEQ и MPI реализаций полностью совпадают
- Эталонная функция подтверждает правильность вычислений
- Обработка всех граничных случаев корректна

### 7.2 Производительность

Результаты измерения производительности для матриц размером 10000х10000 элементов:

**Время выполнения (task_run) - чистые вычисления**

| Режим | Процессы | Время, с | Ускорение |
|-------|----------|----------|-----------|
| seq   | 1        | 1.166    | 1.00      |
| mpi   | 2        | 1.075    | 1.08      |
| mpi   | 4        | 1.091    | 1.07      |
| mpi   | 8        | 1.102    | 1.06      |

**Время выполнения (pipeline) - полный цикл**

| Режим | Процессы | Время, с | Ускорение |
|-------|----------|----------|-----------|
| seq   | 1        | 1.182    | 1.00      |
| mpi   | 2        | 1.044    | 1.13      |
| mpi   | 4        | 1.061    | 1.11      |
| mpi   | 8        | 1.127    | 1.05      |

**Анализ результатов:**

 - Алгоритм масштабируется - ускорение присутствует при любом количестве процессов
 - Оптимальное количество процессов - 2 : максимальное ускорение достигается при минимальных накладных расходах
 - Накладные расходы MPI заметны при увеличении числа процессов
 - Для данной задачи оптимально использовать 2-4 процесса

---
## 8. Выводы

### Достижения

1. Корректность реализации:
   - Обе версии (SEQ и MPI) прошли все функциональные тесты
   - Результаты последовательной и параллельной реализаций полностью идентичны
   - Обеспечена корректная обработка граничных случаев (пустые матрицы, матрицы с одним элементом)

2. Стабильная производительность:
   - Достигнуто ускорение до 1.13× при использовании 2 процессов
   - MPI версия стабильно превосходит последовательную реализацию при любом количестве процессов
   - Алгоритм демонстрирует устойчивую эффективность распараллеливания

3. Эффективное распараллеливание:
   - Алгоритм масштабируется с ростом числа процессов
   - Оптимальная производительность достигается на 2-4 процессах
   - Схема распределения дастрок марицы обеспечивает балансировку нагрузки

### Ограничения и проблемы

1. Коммуникационные накладные расходы:
   - Полный цикл (pipeline) показывает снижение эффективности свыше 4 процессах
   - Накладные расходы MPI становятся значимыми для данной вычислительной задачи

2. Ограничения масштабируемости:
   - Максимальное ускорение достигается при небольшом количестве процессов (2-4)
   - Дальнейшее увеличение процессов не приводит к значительному росту производительности

3. Оптимизация для разоичных сценариев:
   - Для матриц среднего размера оптимально использовать 2 процесса
   - Для более крупных матриц может быть эффективно большее число процессов

---

## 9. Список литературы

1. Документация по курсу «Параллельное программирование» // Parallel Programming Course URL: https://learning-process.github.io/parallel_programming_course/ru/index.html (дата обращения: 15.11.2025).