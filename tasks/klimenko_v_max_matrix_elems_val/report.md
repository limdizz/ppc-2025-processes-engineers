# Максимальное значение элементов матрицы
- Студент: Клименко Владислав Сергеевич, группа 3823Б1ПР2
- Технологии: SEQ, MPI
- Вариант: 13

## 1. Введение
Поиск максимального значения элементов матрицы - одна из базовых задач как в математике, так и в программировании. Программирование простейших версий такого алгоритма - задача достаточно тривиальная. Однако в настоящий момент большинство алгоритмов может быть реализовано при помощи различных технологий, ускоряющих выполнение данного алгоритма, особенно про обработке значительного количества данных. Параллелизация является одной из таких технологий, позволяющей уменьшить время выполнения за счёт распределения нагрузки между процессами и оптимизировать использование вычислительных ресурсов.

В этой работе был реализован алгоритм вычисления максимального значения элементов квадратной матрицы. Реализация происходила при помощи двух технологий: SEQ (последовательная) и MPI (параллельная). Цель - ускорение вычислений за счёт распределения строк матрицы между процессами и параллельного вычисления локальных максимумов.

## 2. Постановка задачи
Дана квадратная матрица размера n * n, элементами которой являются целые числа. Требуется найти наибольший элемент среди всех элементов матрицы.

Формальное определение: пусть задана матрица A = {a_ij}, i,j = 0...n-1. Необходимо вычислить z = max(a_ij).

Пример:
Для матрицы 

            |11 22 34|            
            |34 15 62|
            |72 81 94| 
            
наибольшим элементом является число 94.

Входные данные: std::vector<std::vector<int>> - двумерная матрица целых чисел.

Выходные данные: int - максимальный элемент матрицы.

## 3. Этапы выполнения алгоритмов
Как последовательная, так и параллельная версия алгоритмов предполагают четыре этапа работы программы, представленные как методы соответствующих классов:

1. ValidationImpl() - проверка входных данных.
2. PreProcessingImpl() - дополнительные проверки перед запуском выполнения алгоритма.
3. RunImpl() - выполнение алгоритма.
4. PostProcessingImpl() - проверка конечного результата.

В представленной реализации методы работают следующим образом: 
- ValidationImpl(): проверка на равенство нулю выходных данных.
- PreProcessingImpl(): возвращает true, так как данные проверены на предыдущем шаге.
- RunImpl(): реализация алгоритма поиска максимального значения в квадратной матрице.
- PostProcessingImpl(): возвращает true, так как результат вычислен в предыдущем методе.

### 3.1. Описание последовательной версии (seq/src/ops_seq.cpp)
В последовательной реализации алгоритм последовательно проходит по всем элементам матрицы и запоминает наибольшее значение.

    int max_element = matrix[0][0];
    for (const auto &row : matrix) {
        for (int element : row) {
            max_element = std::max(element, max_element);
        }
    }

Этот вариант реализован в классе KlimenkoVMaxMatrixElemsValSEQ.

### 3.2. Описание параллельной версии (mpi/src/ops_mpi.cpp)
В параллельной версии улевой ранг вычисляет максимум, затем рассылает остальным процессам.

        const auto &matrix = GetInput();

        int rank = 0;
        int size = 1;

        MPI_Comm_rank(MPI_COMM_WORLD, &rank);
        MPI_Comm_size(MPI_COMM_WORLD, &size);

        int n = 0;
        if (rank == 0) {
            n = static_cast<int>(matrix.size());
        }

        MPI_Bcast(&n, 1, MPI_INT, 0, MPI_COMM_WORLD);

        if (n == 0) {
            int result = 0;
            MPI_Bcast(&result, 1, MPI_INT, 0, MPI_COMM_WORLD);
            GetOutput() = result;
            return true;
        }

        int global_max = INT_MIN;

        if (rank == 0) {
            int local_max = INT_MIN;
            for (const auto &row : matrix) {
            for (int v : row) {
                local_max = std::max(local_max, v);
            }
            }
            global_max = local_max;
        }

        MPI_Bcast(&global_max, 1, MPI_INT, 0, MPI_COMM_WORLD);

        GetOutput() = global_max;

        return true;

Этот вариант реализован в классе KlimenkoVMaxMatrixElemsValMPI.

## 4. Схема коммуникации

Процесс 0 определяет размер матрицы и через MPI_Bcast передаёт значение _n_ (размер) всем процессам. Таким образом, все процессы получают значение размера.

Этот же процесс 0 ищет максимальный элемент. Операция MPI_MAX осуществляет поиск глобального максимума. Результат становится доступен всем процессам, затем сохраняется в GetOutput().

### Роли процессов

Ранг 0: Выступает как корневой процесс, вычисляет максимум.

Все ранги: Получают результат от ранга 0.

## 5. Тестирование

Тестирования разделены на модули
functional/main.cpp — функциональные тесты
performance/main.cpp — производительные тесты

### 5.1. Функциональное тестирование
В тестах проверяется корректность работы обеих реализаций на матрицах небольшого размера (3×3, 5×5, 7×7, 10×10, 100×100), а также на матрице, состоящей из одного элемента (1×1), и на нулевой матрице. Значения элементов генерируются последовательно, и это позволяет точно предсказать ожидаемый результат. Тест автоматически запускает как последовательную, так и MPI-реализацию и сверяет результаты с ожидаемым значением.

### 5.2. Тестирование производительности
Для каждой реализации (как MPI, так и последовательной) предусмотрено по два теста:
test_pipeline и test_task, запускающихся через Google Test Framework. Для оценки производительности задаём размер матрицы 15000x15000.

## 6. Условия тестирования
### 6.1. Аппаратное обеспечение/ОС:
- Процессор: Intel(R) Core(TM) i7-12650H 2.30 GHz
- Количество ядер: 10
- Количество потоков: 16
- ОЗУ: 16 Гб
- ОС: Windows 10
- Архитектура: x64

### 6.2. Инструментарий:
- Язык программирования: C++
- Библиотека для параллельного программирования: MPI
- Компилятор: Microsoft Visual C++ (MSVC)
- Тип сборки: Release 
- Фреймворк тестирования: Google Test

## 7. Результаты 
### 7.1. Корректность (функциональные тесты)
Функциональные тесты возвращают корректный результат, равный произведению количества столбцов матрицы на количество строк. В квадратной матрице эти значения равны. 

### 7.2. Производительность
Для замера времени выполнения реализаций алгоритма использовалась команда mpiexec -n N ./ppc_perf_tests  --gtest_filter="*KlimenkoVMaxMatrixElemsVal*", где N - количество процессов. Производилось три запуска работы данной команды, по итогам которых вычислялось среднее время выполнения и рассчитывались ускорение и эффективность. Ниже приведена таблица производительности при размерах матрицы 5000х5000:

| Версия алгоритма       | Кол-во процессов | Время, с | Ускорение | Эффективность |
|-------------|-------|---------|---------|------------|
| seq         | 1     | 0.014   | 1.07    | N/A        |
| mpi         | 2     | 0.012   | 1.16     | 58.33%      |
| mpi         | 4     | 0.012   | 1.21    | 30.35%      |
| mpi         | 8     | 0.013   | 1.71    | 21.42%      |
| mpi         | 16     | 0.017   | 2.76  | 17.27%      |

## 8. Наблюдения
### 8.1. Эффективность
- Эффективность средняя при малом количестве процессов (58.33% при двух процессах).
- Снижается с увеличением количества процессов (до 17.27% при шестнадцати процессах).
### 8.2. Производительность 
- Паралеллизация при поиске максимального значения элементов матрицы на небольшом количестве процессов даёт незначительное ускорение по сравнению с последовательной версией, что мы можем наблюдать при двух процессах.
- Ускорение возрастает с увеличением количества процессов, при достаточно большом количестве процессов (в данном случае 16) наблюдается почти троекратное ускорение.

### 8.3. Выводы
Последовательная и параллельная версии алгоритма были реализованы. Каждая из версий прошла все функциональные тесты, результаты совпадают с предполагаемыми. Параллельная версия демонстрирует ускорение, возрастающее с увеличением количества процессов. Однако эффективность может снижаться при большом количестве процессов.

Тем не менее использование MPI позволяет повышать производительность работы программы, особенно при обработке больших объёмов данных. Данная технология может быть использована как для задач обработки векторов и матриц, так и для более сложных вычислений.

## 9. Источники
1. Сысоев А. В. Лекции по параллельному программированию. — Н. Новгород: ННГУ, 2025.
2. Документация по курсу «Параллельное программирование» // Parallel Programming Course URL: https://learning-process.github.io/parallel_programming_course/ru/index.html
3. Репозиторий курса «Параллельное программирование» // URL: https://github.com/learning-process/ppc-2025-processes-engineers
