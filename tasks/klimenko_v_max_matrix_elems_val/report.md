# Максимальное значение элементов матрицы
- Студент: Клименко Владислав Сергеевич, группа 3823Б1ПР2
- Технологии: SEQ, MPI
- Вариант: 13

## 1. Введение
Поиск максимального значения элементов матрицы - одна из базовых задач как в математике, так и в программировании. Программирование простейших версий такого алгоритма - задача достаточно тривиальная. Однако в настоящий момент большинство алгоритмов может быть реализовано при помощи различных технологий, ускоряющих выполнение данного алгоритма, особенно про обработке значительного количества данных. Параллелизация является одной из таких технологий, позволяющей уменьшить время выполнения за счёт распределения нагрузки между процессами и оптимизировать использование вычислительных ресурсов.

В этой работе был реализован алгоритм вычисления максимального значения элементов квадратной матрицы. Реализация происходила при помощи двух технологий: SEQ (последовательная) и MPI (параллельная). Цель - ускорение вычислений за счёт распределения строк матрицы между процессами и параллельного вычисления локальных максимумов.

## 2. Постановка задачи
Дана квадратная матрица размера n * n, элементами которой являются целые числа. Требуется найти наибольший элемент среди всех элементов матрицы.

Формальное определение: пусть задана матрица A = {a_ij}, i,j = 0...n-1. Необходимо вычислить z = max(a_ij).

Пример:
Для матрицы 

            |11 22 34|            
            |34 15 62|
            |72 81 94| 
            
наибольшим элементом является число 94.

Входные данные: std::vector<std::vector<int>> - двумерная матрица целых чисел.

Выходные данные: int - максимальный элемент матрицы.

## 3. Этапы выполнения алгоритмов
Как последовательная, так и параллельная версия алгоритмов предполагают четыре этапа работы программы, представленные как методы соответствующих классов:

1. ValidationImpl() - проверка входных данных.
2. PreProcessingImpl() - дополнительные проверки перед запуском выполнения алгоритма.
3. RunImpl() - выполнение алгоритма.
4. PostProcessingImpl() - проверка конечного результата.

В представленной реализации методы работают следующим образом: 
- ValidationImpl(): проверка на равенство нулю выходных данных.
- PreProcessingImpl(): возвращает true, так как данные проверены на предыдущем шаге.
- RunImpl(): реализация алгоритма поиска максимального значения в квадратной матрице.
- PostProcessingImpl(): возвращает true, так как результат вычислен в предыдущем методе.

### 3.1. Описание последовательной версии (seq/src/ops_seq.cpp)
В последовательной реализации алгоритм последовательно проходит по всем элементам матрицы и запоминает наибольшее значение.

    int max_element = matrix[0][0];
    for (const auto &row : matrix) {
        for (int element : row) {
            max_element = std::max(element, max_element);
        }
    }

Этот вариант реализован в классе KlimenkoVMaxMatrixElemsValSEQ.

### 3.2. Описание параллельной версии (mpi/src/ops_mpi.cpp)
Строки матрицы распределяются между процессами MPI с использованием блочного распределения. Если размер матрицы не делится на количество процессов, оставшиеся строки распределяются на процессы с меньшими рангами.

    const auto &matrix = GetInput();
    int rank = 0;
    int size = 1;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    int n = static_cast<int>(matrix.size());
    MPI_Bcast(&n, 1, MPI_INT, 0, MPI_COMM_WORLD);
    if (n == 0) {
        if (rank == 0) {
        GetOutput() = 0;
        }
        return true;
    }
    int local_size = n / size;
    int remainder = n % size;
    int start_idx = 0;
    int end_idx = 0;
    if (rank < remainder) {
        start_idx = rank * (local_size + 1);
        end_idx = start_idx + local_size + 1;
    } else {
        start_idx = (remainder * (local_size + 1)) + ((rank - remainder) * local_size);
        end_idx = start_idx + local_size;
    }
    int local_max = INT_MIN;
    for (int i = start_idx; i < end_idx && i < n; i++) {
        for (int j : matrix[i]) {
        local_max = std::max(j, local_max);
        }
    }
    if (local_size == 0 && rank >= n) {
        local_max = INT_MIN;
    }
    int global_max = 0;
    MPI_Allreduce(&local_max, &global_max, 1, MPI_INT, MPI_MAX, MPI_COMM_WORLD);
    GetOutput() = global_max;
    return true;

Этот вариант реализован в классе KlimenkoVMaxMatrixElemsValMPI.

## 4. Схема коммуникации

Процесс 0 определяет размер матрицы и через MPI_Bcast передаёт значение _n_ (размер) всем процессам. Таким образом, все процессы получают значение размера.

Каждый процесс ищет максимальный элемент (локальный максимум) в своём диапазоне строк при помощи std::max. Все процессы обмениваются локальными максимумами. Операция MPI_MAX осуществляет поиск глобального максимума. Результат становится доступен всем процессам, затем сохраняется в GetOutput().

### Роли процессов

Ранг 0: Выступает как корневой процесс, хранит исходную матрицу.

Все ранги: Вычисляют локальный максимум и участвуют в глобальной редукции.

## 5. Тестирование

Тестирования разделены на модули
functional/main.cpp — функциональные тесты
performance/main.cpp — производительные тесты

### 5.1. Функциональное тестирование
В тестах проверяется корректность работы обеих реализаций на матрицах небольшого размера (3×3, 5×5, 7×7, 10×10, 100×100), а также на матрице, состоящей из одного элемента (1×1). Значения элементов генерируются последовательно, и это позволяет точно предсказать ожидаемый результат. Тест автоматически запускает как последовательную, так и MPI-реализацию и сверяет результаты с ожидаемым значением.

### 5.2. Тестирование производительности
Для каждой реализации (как MPI, так и последовательной) предусмотрено по два теста:
test_pipeline и test_task, запускающихся через Google Test Framework. Для оценки производительности задаём размер матрицы 15000x15000.

## 6. Условия тестирования
### 6.1. Аппаратное обеспечение/ОС:
- Процессор: Intel(R) Core(TM) i7-12650H 2.30 GHz
- Количество ядер: 10
- Количество потоков: 16
- ОЗУ: 16 Гб
- ОС: Windows 10
- Архитектура: x64

### 6.2. Инструментарий:
- Язык программирования: C++
- Библиотека для параллельного программирования: MPI
- Компилятор: Microsoft Visual C++ (MSVC)
- Тип сборки: Release 
- Фреймворк тестирования: Google Test

## 7. Результаты 
### 7.1. Корректность (функциональные тесты)
Функциональные тесты возвращают корректный результат, равный произведению количества столбцов матрицы на количество строк. В квадратной матрице они равны. 

### 7.2. Производительность
Для замера времени выполнения реализаций алгоритма использовалась команда mpiexec -n N ./ppc_perf_tests  --gtest_filter="*KlimenkoVMaxMatrixElemsVal*", где N - количество процессов. Производилось три запуска работы данной команды, по итогам которых вычислялось среднее время выполнения и рассчитывались ускорение и эффективность. Ниже приведена таблица производительности при размерах матрицы 15000х15000.:

| Версия алгоритма       | Кол-во процессов | Время, с | Ускорение | Эффективность |
|-------------|-------|---------|---------|------------|
| seq         | 1     | 0.111   | 0.95    | N/A        |
| mpi         | 2     | 0.066   | 1.89     | 94.5%      |
| mpi         | 4     | 0.088   | 2.35    | 58.75%      |
| mpi         | 5     | 0.074   | 2.64    | 52.8%      |

## 8. Наблюдения
### 8.1. Эффективность
- Эффективность высока при малом количестве процессов (94.5% при двух процессах).
- Снижается с увеличением количества процессов (до 52.8% при пяти процессах).
### 8.2. Производительность 
- Паралеллизация при поиске максимального значения элементов матрицы даёт практически линейное ускорение, что мы можем наблюдать при двух процессах.
- Ускорение возрастает с увеличением количества процессов.

### 8.3. Выводы
Последовательная и параллельная версии алгоритма были реализованы. Каждая из версий прошла все функциональные тесты, результаты совпадают с предполагаемыми. Параллельная версия демонстрирует ускорение, возрастающее с увеличением количества процессов. Однако эффективность может снижаться при большом количестве процессов. Это связано с накладными расходами MPI.

Тем не менее использование MPI позволяет повышать производительность работы программы, особенно при обработке больших объёмов данных. Данная технология может быть использована как для задач обработки векторов и матриц, так и для более сложных вычислений.

## 9. Источники
1. Сысоев А. В. Лекции по параллельному программированию. — Н. Новгород: ННГУ, 2025.
2. Документация по курсу «Параллельное программирование» // Parallel Programming Course URL: https://learning-process.github.io/parallel_programming_course/ru/index.html
3. Репозиторий курса «Параллельное программирование» // URL: https://github.com/learning-process/ppc-2025-processes-engineers
