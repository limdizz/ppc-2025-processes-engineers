# Многошаговая схема решения двумерных задач глобальной оптимизации. Распараллеливание путем разделения области поиска.
- Студент: Клименко Владислав Сергеевич, группа 3823Б1ПР2
- Технологии: SEQ, MPI
- Вариант: 12

## 1. Введение
Задачи глобальной оптимизации возникают во многих областях вычислительной математики, физики, машинного обучения и инженерного анализа. В отличие от локальной оптимизации, глобальная оптимизация направлена на поиск абсолютного минимума функции на заданной области, что существенно усложняет задачу из-за наличия локальных экстремумов. Одним из эффективных подходов к решению таких задач является многошаговая схема с адаптивным разбиением области поиска, позволяющая последовательно уточнять перспективные области и отбрасывать заведомо невыгодные.

В данной работе реализован алгоритм двумерной глобальной оптимизации на основе многошаговой схемы с вычислением характеристик подобластей. Реализация выполнена в двух вариантах: последовательная версия (SEQ)  параллельная версия с использованием технологии MPI. Цель работы — исследовать возможность ускорения алгоритма за счёт распараллеливания оценки областей поиска.

## 2. Постановка задачи
Требуется найти точку глобального минимума функции двух переменных: f(x,y) -> min, (x, y) ∈ [x_min, x_max] * [y_min, y_max]

Входные данные:

- функция f(x, y);

- границы области поиска по осям x и y;

- точность ε;

- параметр надёжности r > 1;

- максимальное число итераций.

Выходные данные:

- координаты точки минимума (x_opt, y_opt);

- значение функции в точке минимума f_min;

- количество выполненных итераций;

- флаг сходимости.

## 3. Этапы выполнения алгоритмов
Обе реализации (SEQ и MPI) построены в соответствии с архитектурой фреймворка и включают:

1. ValidationImpl() - проверка корректности входных данных.
2. PreProcessingImpl() - инициализация начальной области поиска и вычисление значения функции в центре области.
3. RunImpl() - выполнение алгоритма.
4. PostProcessingImpl() - поиск лучшего результата и выполнение выхода.

### 3.1. Описание последовательной версии (seq/src/ops_seq.cpp)
Последовательная версия реализована в классе KlimenkoV2DParallelSadSEQ.

Алгоритм выполняет следующие действия:

- хранит список всех текущих регионов;

- последовательно вычисляет характеристику каждого региона;

- выбирает лучший регион;

- выполняет его разбиение;

- проверяет условие остановки.

Все вычисления выполняются в одном потоке, без использования параллелизма.

### 3.2. Описание параллельной версии (mpi/src/ops_mpi.cpp)
Параллелизация выполнена путём разделения множества регионов между MPI-процессами.
Каждый процесс оценивает только свою часть регионов и находит локально лучший.

Архитектура: используется схема master–worker:

Ранг 0 (master):

- хранит глобальный список регионов;

- принимает решения о разбиении;

- управляет критерием остановки.

Остальные ранги (workers):

- вычисляют характеристики выделенных регионов;

- передают лучший результат мастеру.

Коммуникации MPI:

- MPI_Reduce с MPI_MAXLOC — поиск глобально лучшего региона;

- MPI_Bcast — распространение выбранного региона и флага завершения;

- синхронизация результатов после каждой итерации.

Реализация:

Параллельная версия реализована в классе KlimenkoV2DParallelSadMPI.

## 4. Схема коммуникации

Все процессы получают параметры задачи. Каждый процесс вычисляет характеристику своей части регионов. Глобально лучший регион определяется через MPI_Reduce. Ранг 0 выполняет разбиение региона. Проверяется критерий остановки и рассылается всем процессам.

## 5. Тестирование

Тестирования разделены на модули
- functional/main.cpp — функциональные тесты;
- performance/main.cpp — тесты на производительность.

### 5.1. Функциональное тестирование
Функциональные тесты проверяют корректность работы алгоритма на различных функциях:

- сферическая функция;

- квадратичная функция;

- функция Матяса.

Для каждой функции проверяется:

- корректность координат минимума;

- попадание результата в область поиска;

- корректное завершение алгоритма.

### 5.2. Тестирование производительности
Производительные тесты используют вычислительно затратную функцию с большим числом операций, что позволяет адекватно оценить эффект параллелизации.

Тесты выполняются для SEQ и MPI версий с разным числом процессов.

## 6. Условия тестирования
### 6.1. Аппаратное обеспечение/ОС:
- Процессор: Intel(R) Core(TM) i7-12650H 2.30 GHz
- Количество ядер: 10
- Количество потоков: 16
- ОЗУ: 16 Гб
- ОС: Windows 10
- Архитектура: x64

### 6.2. Инструментарий:
- Язык программирования: C++
- Библиотека для параллельного программирования: MPI
- Компилятор: Microsoft Visual C++ (MSVC)
- Тип сборки: Release 
- Фреймворк тестирования: Google Test

## 7. Результаты 
### 7.1. Корректность (функциональные тесты)
Обе реализации успешно проходят все функциональные тесты и находят корректные точки минимума.

### 7.2. Производительность
Замер времени происходил в Docker-контейнере с запуском команды mpirun -n N ./ppc_perf_tests --gtest_filter="* KlimenkoVVMultistep2DSad *", где N - количество процессов. Выполнялось по три запуска выполнения тество на каждое число N, после чего высчитывалось среднее значение времени выполнения алгоритма. Таблица с результатами замеров приведена ниже:

| Версия алгоритма       | Кол-во процессов | Время, с | Ускорение | Эффективность |
|-------------|-------|---------|---------|------------|
| seq         | 1     | 0.084   | 1.03    | N/A        |
| mpi         | 2     | 0.084   | 1.08     | 54.16%      |
| mpi         | 4     | 0.101   | 1.10    | 27.72%      |
| mpi         | 8    | 0.141   | 1.10    | 13.77%      |

## 8. Наблюдения
### 8.1. Эффективность
- Эффективность средняя при малом количестве процессов (54.16% при двух процессах).
- Снижается с увеличением количества процессов (до 13.77% при восьми процессах).
### 8.2. Производительность 
- Паралеллизация при поиске максимального значения элементов матрицы на небольшом количестве процессов даёт незначительное ускорение по сравнению с последовательной версией, что мы можем наблюдать при двух процессах.
- Ускорение умеренно возрастает с увеличением количества процессов.

### 8.3. Выводы
- Многошаговая схема решает задачи глобальной оптимизации, и функциональные тесты, проверяющие в том числе корректность алгоритма, успешно пройдены.
- Параллелизация по областям поиска не даёт ощутимого прироста производительности, хоть ускорение и немного возрастает с увеличением числа процессов.
- Эффективность распараллеливания MPI невысока и понижается пропорционально возрастанию числа процессов.

## 9. Источники
1. Сысоев А. В. Лекции по параллельному программированию. — Н. Новгород: ННГУ, 2025.
2. Документация по курсу «Параллельное программирование» // Parallel Programming Course URL: https://learning-process.github.io/parallel_programming_course/ru/index.html
3. Репозиторий курса «Параллельное программирование» // URL: https://github.com/learning-process/ppc-2025-processes-engineers
