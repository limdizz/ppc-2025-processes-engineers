# Итеративные методы (Зейделя)
- Студент: Клименко Владислав Сергеевич, группа 3823Б1ПР2
- Технологии: SEQ, MPI
- Вариант: 19

## 1. Введение
Решение систем линейных алгебраических уравнений - одна из фундаментальных задач вычислительной математики. Существует множество методов решения систем, которые деляется на две основные категории: прямые и итерационные. Прямые (метод Гаусса, метод Крамера, матричный метод и т.д.) позволяют выстроить алгоритм для нахождения точного решения системы. Итерационные используют повторяющийся процесс, и решение получается в результате последовательных приближений. В данной работе реализован один из таких методов - метод Зейделя (Гаусса-Зейделя).

## 2. Постановка задачи
Дана система Ax = B, где A = (a_ij) - матрица коэффициентов размером n * n, x = (x_1, x_2, ..., x_n)^T - вектор неизвестных, B = (b_1, b_2, ..., b_n)^T - вектор правых частей. 
Условия применения метода Зейделя:
- Матрица A невырождена (detA != 0), т.е. система имеет единственное решение.
- Диагональные элементы a_ii != 0 для всех i = 1, 2, ..., n.
- Для гарантии сходимости метода достаточно, чтобы матрица A удовлетворяла условию диагонального преобладания (доминирования): в каждой строке матрицы элемент, стоящий на главной диагонали, по модулю больше или равен сумме модулей остальных элементов данной строки.

Для применения метода каждое уравнение системы переписывается так, чтобы выразить x_i через остальные переменные. Решение находится последовательным уточнением вектора x(k) на k-й итерации. В качестве начального приближения задаётся произвольный вектор x^(0) (часто x^(0) = 0 или x^(0) = b). Основная идея заключается в том, что при вычислении (k + 1)-го приближения неизвестной x_i учитываются уже вычисленные ранее (k + 1)-ые приближения неизвестных x_1, x_2, ..., x_i-1. 

Итерации продолжаются до выполнения условия сходимости: max |(x_i)^(k+1) - (x_i)^k| < ε; i = 1, ..., n; ε > 0 - заданная точность решения. 

## 3. Этапы выполнения алгоритмов
Как последовательная, так и параллельная версии алгоритмов предполагают четыре этапа работы программы, представленные как методы соответствующих классов:

1. ValidationImpl() - проверка входных данных.
2. PreProcessingImpl() - дополнительные проверки перед запуском выполнения алгоритма.
3. RunImpl() - выполнение алгоритма.
4. PostProcessingImpl() - проверка конечного результата.

### 3.1. Описание последовательной версии (seq/src/ops_seq.cpp)
1. ValidationImpl() - проверяет, что размер матрицы больше нуля, устанавливает размер системы из входных данных.
2. PreProcessingImpl() - возвращает true.
3. RunImpl() - генерирует диагонально доминирующую случайную матрицу A размером n * n; вычисляет вектор правых частей B; проверяет, что диагональные элементы ненулевые; устанавливает точность и максимально число итераций; инициализирует начальное приближение; выполняет итерационный процесс методом Зейделя: для каждой переменной x_i вычисляется новое значение с использованием уже обновлённых значений x_j (j < i), вычисляется квадрат нормы разности между итерациями; процесс продолжается до достижения заданной точности или максимального числа итераций; вычисляется сумма элементов решения и округляется до целого числа.
4. PostProcessingImpl() - возвращает true, если решение найдено.

Вспомогательные функции, использованные при реализации:
- GenerateRandomMatrix - создаёт строго диагонально доминирующую матрицу; внедиагональные элементы - случайные целые числа от 1 до 10, диагональные элементы - сумма модулей внедиагональных элементов + случайное число от 1 до 5.
- ComputeRightHandSide - вычисление правой части системы.
- CheckDiagonalElements - проверка диагональных элементов.
- PerformSeidelIteration - одна итерация метода Зейделя.

### 3.2. Описание параллельной версии (mpi/src/ops_mpi.cpp)
Матрица A распределяется по строкам между процессами. Каждый процесс получается свою часть матрицы (local_matrix) и вектора правых частей (local_b). Используется функция ComputeRowDistribution для равномерного распределения строк.

Итерационный процесс:

- PerformSeidelIteration: каждый процесс вычисляет свои строки решения.
- UpdateLocalXVector: собирает обновленные значения в локальный буфер.
- MPI_Allgatherv: все процессы обмениваются обновленными значениями.
- ComputeLocalDifference: каждый процесс вычисляет локальную разность.
- MPI_Allreduce: суммируются локальные разности для получения глобальной нормы.

Процесс повторяется до сходимости или достижения максимального числа итераций.

Синхронизация:

- Используется MPI_Barrier в PreProcessingImpl для синхронизации процессов.
- MPI_Bcast для распространения результата от root-процесса.

Вспомогательные функции:

- PerformSeidelIteration: выполняет итерацию метода Зейделя для локальных строк.
- UpdateLocalXVector: обновляет локальный вектор x.
- ComputeLocalDifference: вычисляет локальную норму разности.
- InitializeMatrixAndVector: генерирует матрицу и вектор правых частей (только root-процесс).

## 4. Схема коммуникации
### Роли процессов
Процесс 0 (Root):

- Генерирует полную матрицу A и вектор b.
- Распределяет данные между процессами.
- Собирает окончательный результат.
- Распространяет результат всем процессам.

Все процессы:

- Получают свою часть данных (строки матрицы).
- Выполняют итерации метода Зейделя для своих строк.
- Обмениваются обновленными значениями через MPI_Allgatherv.
- Участвуют в вычислении глобальной нормы через MPI_Allreduce.

## 5. Тестирование
Тестирования разделены на модули:
- functional/main.cpp — функциональные тесты.
- performance/main.cpp — производительные тесты.

### 5.1. Функциональное тестирование
Тестирование проводится для различных размеров матрицы:

- Маленькие матрицы: 1×1, 2×2, 3×3.
- Средние матрицы: 5×5, 7×7, 10×10.
- Крупные матрицы: 15×15, 20×20, 30×30, 50×50.

Проверяемые свойства:

- Корректность для диагонально доминирующих матриц.
- Сходимость за конечное число итераций.
- Сравнение результатов SEQ и MPI реализаций.
- Обработка граничных случаев.

### 5.2. Тестирование производительности
Для каждой реализации (как MPI, так и последовательной) предусмотрено по два теста:
test_pipeline (выполнение всей программы) и test_task (выполнение алгоритма), запускающихся через Google Test Framework. Для оценки производительности задаём размер матрицы 2500x2500.

## 6. Условия тестирования
### 6.1. Аппаратное обеспечение/ОС:
- Процессор: Intel(R) Core(TM) i7-12650H 2.30 GHz
- Количество ядер: 10
- Количество потоков: 16
- ОЗУ: 16 Гб
- ОС: Windows 10
- Архитектура: x64

### 6.2. Инструментарий:
- Язык программирования: C++
- Библиотека для параллельного программирования: MPI
- Компилятор: Microsoft Visual C++ (MSVC)
- Тип сборки: Release 
- Фреймворк тестирования: Google Test

## 7. Результаты 
### 7.1. Корректность (функциональные тесты)
Все функциональные тесты успешно пройдены для каждой из реализаций (SEQ и MPI).

### 7.2. Производительность
Для замера времени выполнения реализаций алгоритма использовалась команда mpirun -n N ./ppc_perf_tests  --gtest_filter="*KlimenkoVSeidelMethod*", где N - количество процессов. Замер происходил в Docker-контейнере по причине падающих из-за невыясненных обстоятельств локальных perf-тестов seq-реализации на Windows и сравнивался с результатами perf-тестов, взятых с GitHub. Производилось три запуска работы данной команды, по итогам которых вычислялось среднее время выполнения и рассчитывались ускорение и эффективность. Ниже приведена таблица производительности при размерах матрицы 2500х2500:

| Версия алгоритма       | Кол-во процессов | Время, с | Ускорение | Эффективность |
|-------------|-------|---------|---------|------------|
| seq         | 1     | 0.089   | 0.57    | N/A        |
| mpi         | 2     | 0.16   | 0.68     | 34%      |
| mpi         | 4     | 0.22   | 0.59    | 14.75%      |
| mpi         | 5    | 0.30   | 0.63    | 12.6%      |

## 8. Наблюдения
### 8.1. Эффективность
Эффективность при данных реализациях небольшая. Уменьшается с возрастанием числа процессов. 

### 8.2. Производительность 
Параллелизация алгоритма метода Зейделя не даёт ощутимого прироста производительности. Ускорение остаётся средним вне зависимости от числа процессов (в пределах от 0.5 до 0.7).

### 8.3. Выводы
- Метод Зейделя успешно реализован для решения СЛАУ с диагонально доминирующими матрицами.
- Параллельная MPI-реализация демонстрирует малую эффективность в связи с накладными расходами на выполнение итераций и распределение процессов.
- Обе реализации проходят все функциональные тесты.

## 9. Источники
1. Сысоев А. В. Лекции по параллельному программированию. — Н. Новгород: ННГУ, 2025.
2. Документация по курсу «Параллельное программирование» // Parallel Programming Course URL: https://learning-process.github.io/parallel_programming_course/ru/index.html
3. Репозиторий курса «Параллельное программирование» // URL: https://github.com/learning-process/ppc-2025-processes-engineers
