# Отчет по лабораторной работе

## **"Подсчет предложений в тексте"**, вариант №25

**Студент:** Маковеева Софья Игоревна  
**Группа:** 3823Б1ПР1  
**Преподаватель:** Сысоев Александр Владимирович, доцент

---

## Введение

Подсчет предложений в тексте — распространенная задача в обработке текстовой информации, используемая в лингвистике, анализе данных, SEO-аналитике и других областях. Последовательный алгоритм предполагает линейное сканирование текста. Цель работы — реализовать параллельную версию этого алгоритма с использованием **MPI** (Message Passing Interface), оценить корректность и производительность по сравнению с последовательной версией.

---

## Постановка задачи

**Цель работы:** Реализовать и сравнить последовательную (SEQ) и параллельную (MPI) версии алгоритма подсчета количества предложений в тексте.

**Определение задачи:**
Для заданного текста `T` (строка символов) необходимо определить количество предложений `S`. Предложение считается завершенным при встрече одного из символов-терминаторов: `.`, `!`, `?`. **Важное уточнение алгоритма:** несколько идущих подряд терминаторов (например, "!!!", "?!", "...") считаются **одним** окончанием предложения.

**Ограничения:**
* Входные данные — строка произвольной длины (включая пустую).
* Алгоритм должен корректно обрабатывать последовательности одинаковых терминаторов.
* Для параллельной реализации используется модель передачи сообщений (MPI).
* Результаты обеих реализаций (SEQ и MPI) должны быть идентичны.

---

## Описание алгоритма (последовательная версия)

Алгоритм использует конечный автомат с двумя состояниями для корректного учета множественных терминаторов.

1. Инициализировать счетчик `sentence_count = 0` и флаг `in_sentence_end = false`.
2. Для каждого символа `c` во входной строке:
   * Если `c` — терминатор (`.`, `!`, `?`) и флаг `in_sentence_end` равен `false`:
     - Увеличить `sentence_count` на 1.
     - Установить `in_sentence_end = true`.
   * Если `c` — терминатор, а флаг уже `true`, продолжить (игнорировать повторный терминатор).
   * Иначе (символ не терминатор): сбросить флаг `in_sentence_end = false`.
3. Вернуть значение `sentence_count`.

**Сложность:** O(n), где n — длина текста (количество символов).

### Код последовательной реализации

```cpp
bool SentencesCounterSEQ::RunImpl() {
  const std::string &text = GetInput();
  int sentence_count = 0;
  bool in_sentence_end = false;

  for (char c : text) {
    if (c == '.' || c == '!' || c == '?') {
      if (!in_sentence_end) {
        sentence_count++;
        in_sentence_end = true;
      }
    } else {
      in_sentence_end = false;
    }
  }

  GetOutput() = sentence_count;
  return true;
}

## Схема распараллеливания (MPI)

Параллельный алгоритм решает проблему корректного учета предложений на границах раздела данных между процессами. Для этого каждый процесс получает не только свой фрагмент текста, но и последний символ предыдущего фрагмента.

### Основные этапы алгоритма:

#### 1. Инициализация и передача метаданных:

* Все процессы входят в коммуникатор `MPI_COMM_WORLD`.
* Процесс 0 определяет длину входного текста и рассылает ее всем через `MPI_Bcast`.

#### 2. Распределение данных:

* Вычисляются размеры блоков для каждого процесса: `base_chunk_size = n / size`, `remaining_chars = n % size`. Первые `remaining_chars` процессов получают на 1 символ больше.
* Формируются массивы `chunk_sizes` и `displacements`.
* Текст распределяется между процессами с помощью `MPI_Scatterv`.

#### 3. Решение проблемы граничных терминаторов:

* Процесс 0 собирает последние символы каждого блока (кроме первого) в массив `boundary_chars`.
* Каждый процесс через `MPI_Scatter` получает символ, который находился перед началом его блока (`previous_char`). Для процесса 0 этот символ — `'\0'`.

#### 4. Локальный подсчет с учетом контекста:

* Каждый процесс выполняет функцию `ProcessTextSegment`, которая:
  * Проверяет, не является ли первый символ блока терминатором, идущим сразу после терминатора в `previous_char`. Если да — пропускает всю начальную последовательность терминаторов.
  * Подсчитывает предложения в своем фрагменте, корректно объединяя последовательные терминаторы в одно предложение с помощью `SkipRepeatedPunctuation`.

#### 5. Сбор результатов:

* Локальные счетчики (`local_sentence_count`) суммируются на процессе 0 с помощью `MPI_Reduce` с операцией `MPI_SUM`.
* Итоговое значение (`total_sentences`) рассылается всем процессам через `MPI_Bcast`.

### Ключевой фрагмент MPI-реализации

```cpp
bool SentencesCounterMPI::RunImpl() {
  int rank = 0;
  int size = 0;
  MPI_Comm_rank(MPI_COMM_WORLD, &rank);
  MPI_Comm_size(MPI_COMM_WORLD, &size);

  std::string full_text;
  int text_length = 0;

  if (rank == 0) {
    full_text = GetInput();
    text_length = static_cast<int>(full_text.length());
  }

  MPI_Bcast(&text_length, 1, MPI_INT, 0, MPI_COMM_WORLD);

  if (text_length == 0) {
    GetOutput() = 0;
    return true;
  }

  int base_chunk_size = text_length / size;
  int remaining_chars = text_length % size;

  std::vector<int> chunk_sizes(static_cast<std::size_t>(size));
  std::vector<int> displacements(static_cast<std::size_t>(size));

  int current_displacement = 0;
  for (int i = 0; i < size; ++i) {
    chunk_sizes[static_cast<std::size_t>(i)] = base_chunk_size + (i < remaining_chars ? 1 : 0);
    displacements[static_cast<std::size_t>(i)] = current_displacement;
    current_displacement += chunk_sizes[static_cast<std::size_t>(i)];
  }

  int local_chunk_size = chunk_sizes[static_cast<std::size_t>(rank)];
  std::string local_chunk(static_cast<std::size_t>(local_chunk_size), '\0');

  MPI_Scatterv(rank == 0 ? full_text.data() : nullptr, chunk_sizes.data(), displacements.data(), MPI_CHAR,
               local_chunk.data(), local_chunk_size, MPI_CHAR, 0, MPI_COMM_WORLD);

  std::vector<char> boundary_chars(static_cast<std::size_t>(size));
  if (rank == 0) {
    for (int i = 0; i < size; ++i) {
      int chunk_start = displacements[static_cast<std::size_t>(i)];
      boundary_chars[static_cast<std::size_t>(i)] =
          (chunk_start > 0) ? full_text[static_cast<std::size_t>(chunk_start - 1)] : '\0';
    }
  }

  char previous_char = '\0';
  MPI_Scatter(boundary_chars.data(), 1, MPI_CHAR, &previous_char, 1, MPI_CHAR, 0, MPI_COMM_WORLD);

  int local_sentence_count = ProcessTextSegment(local_chunk, previous_char);

  int total_sentences = 0;
  MPI_Reduce(&local_sentence_count, &total_sentences, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);

  MPI_Bcast(&total_sentences, 1, MPI_INT, 0, MPI_COMM_WORLD);

  GetOutput() = total_sentences;
  return true;
}
## 2. Проверка корректности

Были разработаны и успешно пройдены тесты для различных граничных случаев:

1. **Пустая строка:** `""` → `0`
2. **Строка без терминаторов:** `"Hello world."` → `1`
3. **Простое предложение:** `"Hello! How are you?"` → `2`
4. **Множественные предложения:** `"This is a test. Another sentence! And one more?"` → `3`
5. **Последовательные терминаторы:** `""` → `0`
6. **Смешанные терминаторы на границе:** `"Multiple punctuation...!!!"` → `1`
7. **Текст с переносами строк:** `".!?"` → `1`

**Итог:** Все функциональные тесты пройдены успешно. Результаты SEQ и MPI версий полностью совпадают для всех тестовых случаев.

---

## 3. Оценка производительности

Для оценки производительности использовался синтетический текст объемом ~100 миллионов символов (1 миллион предложений), сгенерированный с равномерным распределением слов и знаков препинания.

### Время выполнения `task_run`

| Режим | Процессы | Время, с | Ускорение |
|-------|----------|----------|-----------|
| seq   | 1        | 0.1009   | 1.000     |
| mpi   | 2        | 0.0939   | 1.075     |
| mpi   | 4        | 0.0647   | 1.559     |

### Время выполнения `pipeline`

| Режим | Процессы | Время, с | Ускорение |
|-------|----------|----------|-----------|
| seq   | 1        | 0.1004   | 1.000     |
| mpi   | 2        | 0.0965   | 1.040     |
| mpi   | 4        | 0.0612   | 1.641     |

### Анализ результатов:

* **MPI-версия на 2 процессах** показывает ускорение всего **4-7.5%** по сравнению с SEQ-версией, что свидетельствует о высоких накладных расходах MPI для данного объема данных.
* При использовании **4 процессов** достигается более значимое ускорение **55-64%**, что демонстрирует потенциал параллельного выполнения.
* **Эффективность** использования вычислительных ресурсов снижается с ростом числа процессов: с **~53%** при 2 процессах до **~40%** при 4 процессах.
* Режим `pipeline` демонстрирует небольшое преимущество перед `task_run` при 4 процессах, что указывает на эффективное перекрытие вычислений и коммуникаций в конвейерной обработке.

---

## Выводы

### 1. Корректность
Обе реализации (SEQ и MPI) демонстрируют полную корректность на всем наборе тестов. Разработанный механизм передачи граничных символов (`previous_char`) успешно решает проблему учета последовательных терминаторов на стыках блоков данных.

### 2. Производительность
* Результаты демонстрируют типичную картину для задач с низкой вычислительной плотностью. При распараллеливании на 2 процесса ускорение минимально (4-7.5%) из-за доминирования коммуникационных накладных расходов (`MPI_Scatterv`, `MPI_Reduce`, `MPI_Scatter`) над вычислительной работой.
* На 4 процессах наблюдается более существенное ускорение (55-64%), что подтверждает принципиальную возможность эффективного распараллеливания задачи при достаточном объеме данных.
* Эффективность параллельных вычислений снижается с 53% на 2 процессах до 39-41% на 4 процессах, что указывает на **ограниченную масштабируемость** алгоритма.

### 3. Анализ алгоритма
* Задача подсчета предложений имеет **низкую арифметическую интенсивность** (мало вычислений на байт данных), поэтому производительность упирается в пропускную способность памяти и задержки операций MPI.
* Разработанный механизм обработки граничных условий увеличивает сложность алгоритма, но необходим для обеспечения корректности.
* Для тестового объема данных (~100 МБ) **точка окупаемости** наступает только при использовании 4 процессов.

### 4. Итог
Использование MPI для подсчета предложений **оправдано только при обработке очень больших текстовых корпусов** (от сотен мегабайт). В этом случае можно получить умеренное ускорение (1.5-2x). Для типичных задач обработки документов (размером в мегабайты) последовательная реализация проще и эффективнее.

---
**Дата выполнения:** 2024 год  
**Фреймворк:** PPC (Parallel Programming Course Framework)  
**Технологии:** C++, MPI, Google Test

