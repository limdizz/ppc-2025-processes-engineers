# Подсчёт числа несовпадающих символов двух строк

- Студент: Перепелкин Ярослав Михайлович, группа 3823Б1ПР1
- Технологии: SEQ | MPI
- Вариант: 27

## 1. Введение
Алгоритм подсчёта несовпадающих символов в двух строках относится к классу задач обработки данных, хорошо поддающихся распараллеливанию благодаря независимости операций сравнения отдельных символов.

Цель работы – разработать параллельную MPI-реализацию данного алгоритма и провести сравнительный анализ её производительности с последовательной версией при различном количестве процессов.

## 2. Постановка задачи
**Определение задачи:**\
Для двух строк требуется вычислить количество позиций, в которых символы различаются. Если строки имеют разную длину, дополнительные символы более длинной строки учитываются как несовпадающие.

**Ограничения:**
- Входные данные – две строки произвольной длины.
- Алгоритм должен корректно обрабатывать строки разной длины.
- Учитывается регистр символов.
- Параллельная реализация использует MPI и должна поддерживать различное количество процессов.
- Результаты последовательной и параллельной версий должны быть идентичны.

## 3. Базовый алгоритм (последовательная версия)
**Входные данные:** две строки `s1` и `s2` произвольной длины.

**Выходные данные:** целое число – количество несовпадающих символов.

**Алгоритм последовательной реализации:**
1. Определить минимальную (`min_len`) и максимальную (`max_len`) длину строк.
2. Сравнить символы на одинаковых позициях в общей части строк (первые `min_len` символов) и подсчитать количество несовпадающих.
3. Добавить разницу длин строк (`max_len - min_len`) к результату – эти символы считаются несовпадающими, так как у них нет пар для сравнения.

**Сложность алгоритма:** `O(min(n,m))`, где `n` и `m` – длины строк `s1` и `s2` соответственно.

Реализация последовательного алгоритма представлена в Приложении 1.

## 4. Схема распараллеливания
Алгоритм параллельно вычисляет количество несовпадающих символов, распределяя обработку общей части строк между процессами и объединяя локальные результаты через коллективную операцию MPI.

### 4.1. Структура параллельного выполнения
- **Инициализация:** Все процессы запускаются в одном коммуникаторе `MPI_COMM_WORLD`. Процесс 0 владеет входными данными.
- **Распределение данных:** Процесс 0 распределяет сегменты данных между всеми процессами с помощью операции `MPI_Scatterv` с балансировкой нагрузки – первые `remainder` процессов получают один дополнительный элемент при неравномерном делении.
- **Локальные вычисления:** Каждый процесс независимо подсчитывает количество несовпадающих символов в назначенном ему сегменте.
- **Агрегация результатов:** Частичные результаты со всех процессов суммируются с помощью операции `MPI_Allreduce`.
- **Формирование итога:** К сумме различий в общей части строк добавляется разница их длин, и финальный результат становится доступен на всех процессах.

### 4.2. Организация процессов
- **Процесс 0** выступает в роли распространителя данных, выполняя операцию `MPI_Scatterv` для распределения сегментов строк.
- **Все процессы** выполняют вычисления на своих сегментах данных и участвуют в коллективной операции `MPI_Allreduce`.
- **Результат** глобального суммирования одновременно становится доступен на всех процессах.
- **Сохраняется равноправие процессов** на этапе вычисления после распределения данных.

### 4.3. Псевдокод параллельной реализации
```cpp
bool RunImpl() {
    // Определение длин строк (только процесс 0)
    if (proc_rank == 0) {
        [s1, s2] = GetInput();
        min_len = min(s1.size(), s2.size());
        max_len = max(s1.size(), s2.size());
    }
    
    // Широковещательная рассылка длин строк
    MPI_Bcast(min_len, max_len);
    
    // Распределение сегментов строк через MPI_Scatterv
    [local_s1, local_s2] = DistributeData(min_len);
    
    // Локальное вычисление различий в сегментах
    local_diff = compare_segments(local_s1, local_s2);
    
    // Глобальное суммирование
    global_diff = MPI_Allreduce(local_diff, MPI_SUM);
    
    // Учет разницы длин и формирование результата
    result = global_diff + (max_len - min_len);
    return result;
}
```

Реализация параллельного алгоритма представлена в Приложении 2.

## 5. Детали реализации

### 5.1. Структура кода
**Ключевые файлы проекта:**
```text
perepelkin_i_string_diff_char_count/
├── common/
│   └── include/common.hpp     - определения типов данных
├── data/                      - тестовые данные для функциональных тестов
├── mpi/
│   ├── include/ops_mpi.hpp    - заголовочный файл MPI-реализации
│   └── src/ops_mpi.cpp        - исходный код параллельной версии
├── seq/
│   ├── include/ops_seq.hpp    - заголовочный файл последовательной версии
│   └── src/ops_seq.cpp        - исходный код последовательной версии
└── tests/
    ├── functional/
    │   └── main.cpp           - функциональные тесты
    └── performance/
        └── main.cpp           - тесты производительности
```

**Основные классы реализации:**
- `PerepelkinIStringDiffCharCountSEQ` – класс последовательной реализации алгоритма.
- `PerepelkinIStringDiffCharCountMPI` – класс параллельной реализации алгоритма.

**Тестовые классы:**
- `PerepelkinIStringDiffCharCountFuncTestProcesses` – класс функционального тестирования.
- `PerepelkinIStringDiffCharCountPerfTestProcesses` – класс тестирования производительности.

**Интерфейс методов реализации:**
- `RunImpl()` – основной метод, содержащий реализацию алгоритма.
- `ValidationImpl()` – проверка корректности начального состояния и входных параметров.
- `PreProcessingImpl()` – подготовительные операции с входными данными.
- `PostProcessingImpl()` – завершающая обработка результатов вычислений.

### 5.2. Особенности реализации и обработка граничных случаев
- **Поддерживаемый набор символов:** Корректно обрабатываются однобайтовые ASCII-символы, включая латиницу, цифры и специальные символы; многобайтовые UTF-8 символы не поддерживаются.
- **Разные длины строк:** Алгоритм корректно обрабатывает строки разной длины, учитывая дополнительные символы как несовпадающие.
- **Пустые строки:** Корректно обрабатываются пустые строки и их комбинации.
- **Регистр символов:** Учитывается различие между заглавными и строчными буквами.

### 5.3. Использование памяти и коммуникации
**Последовательная версия:** `O(N)` – хранение исходных строк длины `N`.

**Параллельная версия:**
- **Хранение данных:** `O(2×N)` – процесс 0 хранит исходные строки длины `N`, каждый из `P` процессов хранит назначенные ему сегменты  длины `N/P`.
- **Обмен данными:**
  - `MPI_Bcast`: `O(1)` – передача длин строк.
  - `MPI_Scatterv`: `O(N)` – распределение сегментов строк по процессам.
  - `MPI_Allreduce`: `O(1)` – сбор частичных сумм с каждого процесса и рассылка результата.

## 6. Тестовая инфраструктура

### 6.1. Аппаратное обеспечение:
| Параметр | Значение                                            |
| -------- | --------------------------------------------------- |
| CPU      | Intel Core i5-12400 (6 cores, 12 threads, 2.50 GHz) |
| RAM      | 32 GB DDR4 (3200 MHz)                               |
| OS       | Windows 11 Home 23H2 (22631.6060)                   |

### 6.2. Программное обеспечение:
| Параметр   | Значение                    |
| ---------- | --------------------------- |
| Компилятор | g++ 14.2.0                  |
| MPI        | Microsoft MPI 10.1.12498.52 |
| Сборка     | Release                     |

### 6.3. Тестовые данные
**Функциональные тесты:** используют заранее подготовленные наборы данных из директории `data/`, содержащие пары строк для сравнения с известным количеством несовпадающих символов.

**Тесты производительности:** данные генерируются программно по следующему алгоритму:
1. Создать 2 базовые строки длиной `N` символов.
2. Внести случайные различия с вероятностью 10%.
3. Масштабировать строки в `M` раз.
4. Добавить разницу длин 0.1%.

Реализация генерации тестовых данных представлена в Приложении 3.

## 7. Результаты и обсуждение

### 7.1 Корректность
Для проверки корректности работы алгоритма проводилось функциональное тестирование на основе Google Test Framework, которое включало:
- Проверку соответствия результатов заранее определённым ожидаемым значениям.
- Анализ работы алгоритма на граничных случаях:
  - Пустые строки и строки разной длины.
  - Учет регистра символов.
  - Обработка специальных символов.

**Перечень функциональных тестов:**
| Описание теста  | Файл с данными | Ожидаемое количество несовпадающих символов |
| ---------- | -------- |--|
| Первая строка пустая | `first_empty.txt` | 6 |
| Вторая строка пустая | `second_empty.txt` | 6 |
| Обе строки пустые | `empty_strings.txt` | 0 |
| Идентичные короткие строки | `identical_short.txt` | 0 |
| Один несовпадающий символ | `single_diff.txt` | 1 |
| Строки разной длины | `diff_length_extra_chars.txt` | 1 |
| Полностью различные строки | `completely_different.txt` | 4 |
| Строки с пробелами | `with_spaces.txt` | 2 |
| Учет регистра символов | `case_sensitive.txt` | 1 |
| Длинные строки с частичными различиями | `long_strings_partial_diff.txt` | 1 |
| Длинные строки с различиями в конце | `long_diff_tail.txt` | 3 |
| Специальные символы | `special_chars.txt` | 1 |

Результаты функционального тестирования подтвердили корректность реализации алгоритма – все тестовые сценарии были успешно пройдены.

### 7.2 Производительность

**Параметры тестирования:**
- **Данные:** 2 строки длиной 1024 миллиона символов.
- **Метрики:**
  - Абсолютное время выполнения.
  - Ускорение относительно последовательной версии.
  - Эффективность параллелизации – рассчитывается как `(ускорение / количество процессов) × 100%`.
- **Сценарии измерения:**
  - **Полный цикл (pipeline)** – измерение времени выполнения всей программы (`Validation`, `PreProcessing`, `RunImpl`, `PostProcessing`).
  - **Только вычислительная часть (task_run)** – измерение времени только этапа выполнения алгоритма (`RunImpl`).

**Результаты полного цикла выполнения:**
| Режим | Процессы | Время, с | Ускорение | Эффективность |
| ----- | -------- | -------- | --------- | ------------- |
| seq   | 1        | 0.298656 | 1.000     | N/A           |
| mpi   | 2        | 0.548191 | 0.545     | 27.24%        |
| mpi   | 4        | 0.451612 | 0.661     | 16.53%        |

**Результаты вычислительной части:**
| Режим | Процессы | Время, с | Ускорение | Эффективность |
| ----- | -------- | -------- | --------- | ------------- |
| seq   | 1        | 0.295377 | 1.000     | N/A           |
| mpi   | 2        | 0.546585 | 0.540     | 27.02%        |
| mpi   | 4        | 0.438883 | 0.673     | 16.83%        |

**Анализ результатов (на основе сценария task_run):**
- **Производительность:** MPI-реализация демонстрирует замедление относительно последовательной версии (ускорение 0.54-0.67×).
- **Эффективность параллелизации:** На 2 процессах показатель эффективности составляет 27% с последующим снижением до 17% при использовании 4 процессов.
- **Ограничения масштабируемости:** Затраты на коммуникацию между процессами занимают значительное время, что приводит к снижению эффективности.

## 8. Выводы
**Реализация и тестирование:**
- Успешно разработаны последовательная и параллельная реализации алгоритма подсчёта несовпадающих символов двух строк.
- Проведенное функциональное тестирование подтвердило корректность работы обеих версий на различных наборах данных.

**Результаты производительности:**
- Параллельная реализация алгоритма показывает снижение производительности относительно последовательной версии: ускорение составляет 0.54 при использовании 2 процессов и 0.67 при 4 процессах.
- Эффективность параллелизации низкая: 27% на 2 процессах с последующим снижением до 17% на 4 процессах.

**Выявленные проблемы:**
- Производительность ограничена скоростью доступа к данным: каждый процесс выполняет минимальный объём вычислений, и основная доля времени уходит на чтение символов из памяти.
- Для задач с такой структурой данных параллелизация не даёт выигрыша, поскольку накладные расходы на организацию параллельного выполнения превышают возможный прирост производительности.

## 9. Источники
1. Документация по курсу «Параллельное программирование» // Parallel Programming Course URL: https://learning-process.github.io/parallel_programming_course/ru/index.html (дата обращения: 31.10.2025).
2. Сысоев А. В. «Коллективные и парные взаимодействия» // Лекции по дисциплине «Параллельное программирование для кластерных систем». — 2025.
3. Коллективные функции MPI // Microsoft URL: https://learn.microsoft.com/ru-ru/message-passing-interface/mpi-collective-functions (дата обращения: 01.11.2025).
4. std::transform_reduce // cppreference.com URL: https://en.cppreference.com/w/cpp/algorithm/transform_reduce.html (дата обращения: 09.11.2025).

## Приложения

### Приложение №1. Реализация последовательной версии алгоритма
```cpp
bool PerepelkinIStringDiffCharCountSEQ::RunImpl() {
  const auto &[s1, s2] = GetInput();
  const size_t min_len = std::min(s1.size(), s2.size());
  const size_t max_len = std::max(s1.size(), s2.size());

  int diff = std::transform_reduce(s1.begin(), s1.begin() + min_len, s2.begin(), 0,
                                   std::plus<>(), std::not_equal_to<>());

  GetOutput() = diff + static_cast<int>(max_len - min_len);
  return true;
}
```

### Приложение №2. Реализация параллельной версии алгоритма
```cpp
bool PerepelkinIStringDiffCharCountMPI::RunImpl() {
  size_t min_len = 0;
  size_t max_len = 0;

  if (proc_rank_ == 0) {
    const auto &[s1, s2] = GetInput();
    min_len = std::min(s1.size(), s2.size());
    max_len = std::max(s1.size(), s2.size());
  }

  MPI_Bcast(&min_len, 1, MPI_INT, 0, MPI_COMM_WORLD);
  MPI_Bcast(&max_len, 1, MPI_INT, 0, MPI_COMM_WORLD);

  std::vector<char> local_s1;
  std::vector<char> local_s2;
  DistributeData(min_len, local_s1, local_s2);

  int local_diff = std::transform_reduce(local_s1.begin(), local_s1.end(), local_s2.begin(), 0, std::plus<>(),
                                         std::not_equal_to<>());

  int global_diff = 0;
  MPI_Allreduce(&local_diff, &global_diff, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);

  GetOutput() = global_diff + static_cast<int>(max_len - min_len);
  return true;
}
```

```cpp
void PerepelkinIStringDiffCharCountMPI::DistributeData(size_t min_len, std::vector<char> &local_s1,
                                                       std::vector<char> &local_s2) {
  const int base_size = static_cast<int>(min_len / proc_num_);
  const int remainder = static_cast<int>(min_len % proc_num_);

  std::vector<int> counts(proc_num_);
  std::vector<int> displacements(proc_num_);

  if (proc_rank_ == 0) {
    for (int i = 0, offset = 0; i < proc_num_; i++) {
      counts[i] = base_size + (i < remainder ? 1 : 0);
      displacements[i] = offset;
      offset += counts[i];
    }
  }

  const int local_size = base_size + (proc_rank_ < remainder ? 1 : 0);
  local_s1.resize(local_size);
  local_s2.resize(local_size);

  const char *s1_data = nullptr;
  const char *s2_data = nullptr;
  if (proc_rank_ == 0) {
    const auto &[s1, s2] = GetInput();
    s1_data = s1.data();
    s2_data = s2.data();
  }

  MPI_Scatterv(s1_data, counts.data(), displacements.data(), MPI_CHAR, local_s1.data(), local_size, MPI_CHAR, 0,
               MPI_COMM_WORLD);
  MPI_Scatterv(s2_data, counts.data(), displacements.data(), MPI_CHAR, local_s2.data(), local_size, MPI_CHAR, 0,
               MPI_COMM_WORLD);
}
```

### Приложение №3. Генерация тестовых данных для тестов производительности
```cpp
 static std::tuple<std::string, std::string, int> GenerateTestData(size_t base_length, unsigned int seed,
                                                                    float diff_rate = 0.15F, int scale_factor = 1) {
    std::mt19937 gen(seed);

    std::string base_str1;
    std::string base_str2;
    base_str1.reserve(base_length);
    base_str2.reserve(base_length);

    const std::string charset = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789";
    std::uniform_int_distribution<size_t> char_dist(0, charset.size() - 1);
    std::uniform_real_distribution<double> diff_dist(0.0, 1.0);

    int base_diff_count = 0;

    // Generate base pattern
    for (size_t i = 0; i < base_length; ++i) {
      char c1 = charset[char_dist(gen)];
      base_str1.push_back(c1);

      if (diff_dist(gen) < diff_rate) {
        char c2 = charset[char_dist(gen)];
        while (c2 == c1) {
          c2 = charset[char_dist(gen)];
        }
        base_str2.push_back(c2);
        base_diff_count++;
      } else {
        base_str2.push_back(c1);
      }
    }

    // Scale strings by repeating the base pattern
    std::string str1;
    std::string str2;
    size_t scaled_length = base_length * scale_factor;
    str1.reserve(scaled_length);
    str2.reserve(scaled_length);

    for (int i = 0; i < scale_factor; ++i) {
      str1 += base_str1;
      str2 += base_str2;
    }
    int total_diff_count = base_diff_count * scale_factor;

    // Extend first string to be longer
    size_t extension_length = scaled_length / 1000;  // 0.1% extension
    for (size_t i = 0; i < extension_length; ++i) {
      str1.push_back(charset[char_dist(gen)]);
    }
    total_diff_count += static_cast<int>(extension_length);

    return {str1, str2, total_diff_count};
  }
```
