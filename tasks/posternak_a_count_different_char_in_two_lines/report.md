# Подсчет количества различающихся символов в двух строках

- Студент: Постернак Алексей Николаевич, группа 3823Б1ПР2
- Технологии: SEQ | MPI
- Вариант: 27

## 1. Введение

Задача подсчета количества различающихся символов в двух строках имеет большую значимость в обработке текстовых данных.

**Цель:**
Разработать параллельную (MPI) реализацию алгоритма подсчета количества различающихся символов в двух строках и сравнить производительность с последовательным (SEQ) алгоритмом на различных объемах данных.

## 2. Постановка задачи

**Задача:**
Для двух строк требуется подсчитать количество позиций, в которых символы различны. В случае, если строки имеют различную длину, то в результате нужно прибавить разность этих длин 

**Ограничения:**
- Строки должны быть непустыми
- Корректная обработка строк различной длины
- Учет регистра
- Результаты последовательного и параллельного алгоритма должны быть идентичными

## 3. Базывый алгоритм (последовательный)

**Входные данные:**
Две строки произвольной произвольной длины (`s1` и `s2`).

**Выходные данные:**
Количество различных символов (целое число).

**Реализация алгоритма:**
1. Определяем максимальную и минимальную длину строк для обработки строк разлиной длины (`min_len` и `max_len`).
2. Проходимся циклом до `min_len`, считаем количество различающихся символов и записываем результат в `diff_count`.
3. Добавляем разность `max_len` и `min_len` к `diff_count`.

Полная реализация алгоритма находится в Приложении.

## 4. Схема распараллеливания

**Топология:**
В представленном алгоритме используется декартова топология.

**Распределение данных:**
- Нулевой процесс хранит исходные данные двух сравниваемых строк и рассылает данные:
    - Создаются вектора `s1_proc_parts` и `s2_proc_parts`, которые будет хранить равные части строк `s1` и `s2` соответсвенно (остаток будет прибавляться к последней части)
    - Производится разбиение строк `s1` и `s2` на равные части (с учетом остатка)
    - С помощью функций `MPI_Send()` отправляет остальным процессам информацию о их длине части и сами части строки, при этом оставляя себе начальную часть строки
- Остальные процессы получают данные от нулевого с помощью функции `MPI_Recv()`
- Выполняются параллельные вычисления различающихся символов в кусках строк `s1` и `s2`
- Локальные результаты суммируются в общий и отправляются всем процессам с помощью функции `MPI_Allreduce()` и учитывается разница длин строк 's1' и 's2'

Полная реализация алгоритма находится в Приложении.

## 5. Детали реализации

**Структура проекта:**
```
- posternak_a_count_different_char_in_two_lines // корень проекта
    - common/include/common.hpp                 // определение типов входных и выходных данных
    - mpi                                       // реализация параллельного алгоритма
        - include/ops_mpi.hpp                   // объявление функций
        - src/ops_mpi.cpp                       // реализация функций
    - seq                                       // реализация последовательного алгоритма
        - include/ops_mpi.hpp                   // объявление функций
        - src/ops_mpi.cpp                       // реализация функций
    - test                                      // тестирование алгоритмов mpi и seq
        - functional/main.cpp                   // функциональные тесты
        - perfomance/main.cpp                   // тесты на производительность
    - info.json                                 // информация о студенте
    - report.md                                 // отчет
    - settings.json                             // настройки проекта
```

**Ключевые классы:**
- `PosternakACountDifferentCharInTwoLinesSEQ` - последовательная реализация алгоритма
- `PosternakACountDifferentCharInTwoLinesMPI` - параллельная реализация алгоритма

**Ключевые функции:**
- `ValidationImpl()` - проверка входных данных
- `PreProcessingImpl()` - предварительные вычисления  
- `RunImpl()` - реализация SEQ/MPI алгоритма
- `PostProcessingImpl()` - завершающая обработка

**Частные случаи:**
Предварительное условие - строки должны быть непустыми

## 6. Экспериментальное окружение

**Аппаратное обеспечение:**
- Процессор: Intel Core i7-11800H @ 2.30GHz
- Ядра: 16 шт.
- ОЗУ: 16 ГБ
- ОС: Kubuntu 25.10

**Программный инструментарий:**
- Компилятор: g++ 15.2.0
- Тип сборки: Release
- Стандарт C++: C++23
- MPI: Open MPI 5.0.8

**Тестовое окружение**
```bash
PPC_NUM_PROC=1,2,4
```

## 7. Результаты

### 7.1 Корректность

Все функциональные тесты были успешно пройдены:
1. Строки одинаковой длины с различием в 1 символ.
2. Строки разной длины.
3. Строки с 1 символом.
4. Одиннаковые строки. 
5. Строки с цифрами.
6. Строки со специальными символами.
7. Длинные строки.

SEQ и MPI версии выдают идентичные результаты для всех тестовых случаев.

### 7.2 Производительность

**Результаты замера времени выполнения MPI и SEQ алгоритмов для строк, длинной 10.000.000 символов:**

| Режим | Количество процессов | Время, с | Ускорение | Эффективность |
|-------|----------------------|----------|-----------|---------------|
| SEQ   | 1                    | 17.14    | 1.00      | N/A           |
| MPI   | 1                    | 17.66    | 0.97      | 97%           |
| MPI   | 2                    | 11.00    | 1.56      | 78%           |
| MPI   | 4                    | 7.72     | 2.22      | 56%           |


**Формула ускорения:** Ускорение = Время SEQ / Время MPI

**Формула эффективности:** Эффективность = (Ускорение / Количество процессов) × 100%

### 7.3. Анализ результатов

**Лучшее ускорение:** 2.22 на 4 процессах

**Эффективность:** При увеличении числа процессов снижается показатель эффективности

## 8. Выводы

В результате выполнения проекта были разработаны и протестированы последовательный (SEQ) и параллельный (MPI) алгоритма подсчета различающихся символов в двух строках.

Параллельный алгоритм работает быстрее последовательного на больших данных, однако на малых немного уступает по времени выполнения от последовательного алгоритма из-за обмена данными между процессами.

При увеличении числа ядер для параллельного алгоритма уменьшается эффективность. В основном, это связанно с увеличением объема обмена данными между процессами.

Итого, для малых объемов данных лучше использовать последовательный (SEQ) алгоритм, а для больших объемов данных - параллельный (MPI) алгоритм.

## 9. Литература

1. Документация по курсу: "Параллельное программирование": https://learning-process.github.io/parallel_programming_course/ru/index.html (Оболенский А.А, Нестеров А.Ю)
2. Лекции по курсу "Параллельное программирование". (Сысоев А.В. ННГУ 2025 г.)
3. Документация по MPI: https://www.open-mpi.org/

## Приложение

`ops_seq.cpp:`

```cpp
bool PosternakACountDifferentCharInTwoLinesSEQ::RunImpl() {
  std::pair<std::string, std::string> &lines = GetInput();
  std::string s1 = lines.first;
  std::string s2 = lines.second;

  int diff_count = 0;
  size_t min = 0;
  size_t max = 0;
  size_t s1_len = s1.length();
  size_t s2_len = s2.length();
  // Находим максимальную и минимальную длину строк
  if (s1_len >= s2_len) {
    min = s2_len;
    max = s1_len;
  } else {
    min = s1_len;
    max = s2_len;
  }
  // Сравниваем символы
  for (size_t i = 0; i < min; i++) {
    if (s1[i] != s2[i]) {
      diff_count++;
    }
  }
  // Учитываем разницу в длине
  diff_count += static_cast<int>(max - min);
  GetOutput() = diff_count;
  return true;
}
```

`ops_mpi.cpp:`

```cpp
bool PosternakACountDifferentCharInTwoLinesMPI::RunImpl() {
  int rank = 0;
  MPI_Comm_rank(MPI_COMM_WORLD, &rank);

  int size = 0;
  MPI_Comm_size(MPI_COMM_WORLD, &size);

  std::string s1;
  std::string s2;

  int s1_len = 0;
  int s2_len = 0;

  // Только процесс 0 содержт все исходные данные
  if (rank == 0) {
    std::pair<std::string, std::string> &lines = GetInput();
    s1 = lines.first;
    s2 = lines.second;
    s1_len = static_cast<int>(s1.length());
    s2_len = static_cast<int>(s2.length());
  }

  // Передаем длину строк всем процессам
  MPI_Bcast(&s1_len, 1, MPI_INT, 0, MPI_COMM_WORLD);
  MPI_Bcast(&s2_len, 1, MPI_INT, 0, MPI_COMM_WORLD);

  // Создаем вектора, которые будут хранить равные части строк
  std::vector<std::string> s1_proc_parts;
  std::vector<std::string> s2_proc_parts;

  // Разделяем строки в процессе 0
  if (rank == 0) {
    int min_len = std::min(s1_len, s2_len);

    int local_len = min_len / size;
    int remainder = min_len % size;

    int start = 0;
    for (int i = 0; i < size; i++) {
      int part_len = local_len;
      if (i == size - 1) {
        part_len += remainder;
      }

      s1_proc_parts.push_back(s1.substr(start, part_len));
      s2_proc_parts.push_back(s2.substr(start, part_len));
      start += part_len;
    }

    // Рассылаем каждому процессу свою часть строки
    for (int proc = 1; proc < size; proc++) {
      int part_len = static_cast<int>(s1_proc_parts[proc].length());

      MPI_Send(&part_len, 1, MPI_INT, proc, 0, MPI_COMM_WORLD);
      MPI_Send(s1_proc_parts[proc].c_str(), part_len, MPI_CHAR, proc, 1, MPI_COMM_WORLD);
      MPI_Send(s2_proc_parts[proc].c_str(), part_len, MPI_CHAR, proc, 2, MPI_COMM_WORLD);
    }
    // Процесс 0 оставлет себе перую часть строки
    s1 = s1_proc_parts[0];
    s2 = s2_proc_parts[0];
  } else {
    // Получение данных, отправленных процессом 0, другими процессами
    int part_len = 0;
    MPI_Recv(&part_len, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);

    s1.resize(part_len);
    s2.resize(part_len);

    MPI_Recv(s1.data(), part_len, MPI_CHAR, 0, 1, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
    MPI_Recv(s2.data(), part_len, MPI_CHAR, 0, 2, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
  }

  // Параллельное вычисление различных символов
  int process_count = 0;
  int part_len = static_cast<int>(s1.length());
  for (int i = 0; i < part_len; i++) {
    if (s1[i] != s2[i]) {
      process_count++;
    }
  }

  // Получение общего результата
  int count = 0;
  MPI_Allreduce(&process_count, &count, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);

  count += std::abs(s1_len - s2_len);
  GetOutput() = count;

  return true;
}

```