# Нахождение наиболее близких соседних элементов вектора

- Студент: Романов Михаил Павлович, группа 3823Б1ПР4
- Технология: SEQ | MPI
- Вариант: 7

## 1. Введение

Задача нахождения наиболее близких соседних элементов вектора является фундаментальной операцией в анализе данных, обработке сигналов и задачах оптимизации. Она позволяет быстро выявлять участки минимальной локальной изменчивости в последовательности. При работе с массивами данных больших объемов последовательный подход становится неэффективным, что обуславливает необходимость в разработке параллельных решений.

Работа посвящена разработке алгоритма для решения нахождения близких элементов, а также анализу возможностей его параллельного исполнения.

## 2. Постановка задачи

Дан вектор целых чисел A размера N, N >=2. Требуется найти такие соседние индексы, что их разница среди всех пар будет минимальна
**Входные данные:** Вектор целых чисел A.
**Выходные данные** Пара индексов, соответствующих минимальной паре.

## 3. Базовый алгоритм (Последовательный)

Последовательный алгоритм состоит в линейном сканировании вектора A.
1. Инициализация. Вычисление минимальной разницы и начального индекса на основе первой пары
2. Итерация. Вычисление текущей разницы и замены, если текущая меньше минимальной.
```cpp

  for (size_t i = 1; i < size - 1; ++i) {
    int current_diff = std::abs(v[i + 1] - v[i]);

    if (current_diff < min_diff) {
      min_diff = current_diff;
      min_idx = static_cast<int>(i);
    }
  }

```

## 4. Параллелизация

Для параллелизации используется декомпозиция данных по блокам, чтобы распределить нагрузку между процессами.

Входной вектор A делится на P блоков(P - кол-во процессов). Распределение осуществляется корневым процессом (Rank 0) с помощью MPI_Scatterv, что позволяет обрабатывать блоки переменной длины в зависимости от остатка.

Особенность задачи в необходимости проверять пары, которые расположены на границах блоков, которые принадлежат разным процессам.

**1. Обмен граничными данными:** Каждый процесс (кроме Rank 0) должен знать последний элемент своего левого соседа. Это достигается с помощью блокирующей функции MPI_Sendrecv, которая позволяет безопасно обменяться данными между соседними процессами.

Каждый процесс отправляет свой последний элемент следующему процессу (rank + 1).

Каждый процесс принимает последний элемент от предыдущего процесса (rank - 1).

**2. Обработка границы:** После обмена каждый процесс проверяет разницу между своим элементом и полученным граничным, если разница минимальна идёт обновление локального результата.

После нахождение локальной минимальной разницы и соответствующего глобального индекса идёт нахождение глобального минимума.

## 5. Детали реализации
```
 romanov_m_closest_elem_vec/
??? common/include/common.hpp
??? seq/include/ops_seq.hpp
??? seq/src/ops_seq.cpp
??? mpi/include/ops_mpi.hpp
??? mpi/src/ops_mpi.cpp
??? tests/functional/main.cpp
???tests/performance/main.cpp
```
1.**Генерация данных:** Для тестов производительности используется детерминированная генерация 20 млн элементов, которая принудительно выполняет умножение в 64-битном пространстве (static_cast<long long>(i) * ...) для предотвращения ошибки переполнения 32-битного знакового целого.

2.Для корректной работы MPI_MINLOC используется структура Result {int diff, int idx} и стандартный тип MPI_2INT.

3.Крайний случай $N < 2$: Проверяется в ValidationImpl(), предотвращая запуск невозможной операции.

Каждый процесс хранит полную копию входных данных (из-за фреймворка) и дополнительно свой локальный блок данных. Обмен данными минимален: всего одно целочисленное значение передается между соседними процессами. Общая память линейно зависит от N и P, хотя большая часть памяти приходится на неизменяемые копии входного вектора.

## 6. Тестовое окружение
* Аппаратное обеспечение/Операционная система: AMD Ryzen 5 7640HS, 6 ядер/12 потоков, LPDDR5X 16 GB, Windows 11.
* Инструменты сборки: Visual studio 2022 community release. CMake 4.2.0.
* Переменные окружения: PPC_NUM_THREADS=PPC_NUM_PROC=1/2/4/6/8/12/16, PPC_PERF_MAX_TIME=10000.
* Данные:  Вектор из N = 20,000,000 элементов.

## 7. Результаты

### 7.1 Корректность
Корректность проверялась с использованием набора функциональных тестов, включая:

Тест на минимальный размер (N=2).

Тест на нулевую разницу (одинаковые соседние элементы).

Тесты с минимальной разницей на границах (первый и последний элемент всего вектора, а также на границах между блоками процессов).

Проверка приоритета по наименьшему индексу $i$ в случае равных минимальных разниц.

Результаты параллельной версии (MPI) полностью совпали с результатами последовательной (SEQ) реализации для всех тестовых случаев.
### 7.2 Производительность
|Режим|Число процессов|Время(мс)|Ускорение|Эффективность|
|-----|---------------|---------|---------|-|
|seq|1|304|1||
|mpi|4|362|0.83|20.8%|
|mpi|8|255|1.19|14.9%|
|mpi|12|212|1.43|11.9%|
|mpi|16|143|2.12|13.3%|

Алгоритм демонстрирует ускорение в 2.12 с 16 процессами по сравнение с 1. На протяжение увеличения процессов идёт линейны рост ускорения.

P=4 наблюдается замедление. Это указывает на то, что накладные расходы на параллелизацию (инициализация MPI, распределение данных через MPI_Scatterv, обмен границами и редукция через MPI_Allreduce) на данном этапе превышают время, сэкономленное за счет параллельной обработки.

Эффективность остается крайне низкой во всем диапазоне тестирования, что подтверждает значительное влияние коммуникационных и синхронизационных издержек.

### 8. Заключение
Была успешно разработана и протестирована параллельная реализация задачи нахождения наиболее близких соседних элементов вектора с использованием MPI. Алгоритм, основанный на декомпозиции данных и проверке границ, показал низкую эффективность из-за доминирования коммуникационных издержек над простыми локальными вычислениями. Наблюдается замедление при малом числе процессов и слабое ускорение при увеличении числа процессов до 16.

### 9. Источники

1.  Microsoft MPI : документация [Электронный ресурс] // Microsoft Learn. – URL: https://learn.microsoft.com/ru-ru/message-passing-interface/microsoft-mpi
2. Сысоев А. В. Курс лекций по параллельному программированию.
3. Parallel programming course [Электронный ресурс] : документация URL: https://learning-process.github.io/parallel_programming_course/ru/common_information/processes_tasks.html